{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c05513",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, log_loss\n",
    "\n",
    "# Load Dataset\n",
    "df = pd.read_csv('merged_dataset_VF03.csv')\n",
    "\n",
    "# Drop columns that are IDs or irrelevant to the math\n",
    "X = df.drop(['Customer ID', 'Churn Value', 'Churn Category', 'Churn Reason'], axis=1, errors='ignore')\n",
    "y = df['Churn Value']\n",
    "\n",
    "# Strategic Split: 80/20 with stratification to handle class imbalance\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511834f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grouping features for specific mathematical treatments\n",
    "binary_cols = [col for col in X.columns if X[col].nunique() == 2]\n",
    "categorical_cols = ['Contract', 'Internet Type', 'Payment Method', 'Offer']\n",
    "numeric_cols = ['Tenure in Months', 'Monthly Charge', 'Total Charges']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # OneHot for categories, handle unknown values for production safety\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols),\n",
    "        # Pass-through or binary encoding for simple flags\n",
    "        ('bin', OneHotEncoder(drop='if_binary', sparse_output=False), binary_cols),\n",
    "        # Standardize numeric features for Convex Solver stability (Crucial for L-BFGS)\n",
    "        ('num', StandardScaler(), numeric_cols)\n",
    "    ])\n",
    "\n",
    "# Define the full Pipeline: Preprocessing + Solver\n",
    "# Using SAGA as it supports L1/L2 and is faster for large datasets as per your README\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', LogisticRegression(solver='saga', penalty='l2', max_iter=2000, tol=1e-4))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e52033",
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = [\n",
    "    ('L-BFGS (Quasi-Newton)', 'lbfgs'),\n",
    "    ('SAGA (Stochastic)', 'saga'),\n",
    "    ('Liblinear (Coordinate Descent)', 'liblinear')\n",
    "]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "for name, s in solvers:\n",
    "    # Build temporary pipeline for comparison\n",
    "    test_pipe = Pipeline(steps=[\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('classifier', LogisticRegression(solver=s, max_iter=100, warm_start=True))\n",
    "    ])\n",
    "    \n",
    "    losses = []\n",
    "    # Manually iterate to capture the convergence path\n",
    "    for i in range(20):\n",
    "        test_pipe.fit(X_train, y_train)\n",
    "        losses.append(log_loss(y_train, test_pipe.predict_proba(X_train)))\n",
    "    \n",
    "    plt.plot(losses, label=name)\n",
    "\n",
    "\n",
    "\n",
    "plt.title(\"Empirical Investigation: Solver Convergence Path\")\n",
    "plt.xlabel(\"Epochs/Iterations\"); plt.ylabel(\"Log Loss\"); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7faf757a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the production-ready model\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Print performance metrics to verify no degradation\n",
    "print(classification_report(y_test, pipeline.predict(X_test)))\n",
    "\n",
    "# EXPORT: This replaces your 8 joblib files\n",
    "import os\n",
    "if not os.path.exists('models'): os.makedirs('models')\n",
    "joblib.dump(pipeline, 'models/churn_pipeline.joblib')\n",
    "\n",
    "print(\"SUCCESS: Pipeline exported as models/churn_pipeline.joblib\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
